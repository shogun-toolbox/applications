{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shogun as sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "COUNTRIES = ['austria', 'belgium', 'germany', 'italy', 'netherlands']\n",
    "LANGUAGE = {'austria'    : 'german',\n",
    "            'belgium'    : 'dutch',\n",
    "            'germany'    : 'german',\n",
    "            'italy'      : 'italian',\n",
    "            'netherlands': 'dutch'}\n",
    "\n",
    "PREFIX = {'german': 'de', 'dutch': 'nl', 'italian': 'it'}\n",
    "\n",
    "POPULATION = {'austria'    : 9003354,\n",
    "              'belgium'    : 11586640,\n",
    "              'germany'    : 83768122,\n",
    "              'italy'      : 60467045,\n",
    "              'netherlands': 17132636}\n",
    "\n",
    "processed_data_path = Path.cwd() / 'data' / 'processed'\n",
    "# keywords_path = Path.cwd() / 'revised_keywords'\n",
    "# models_path = Path.cwd() / 'influenza_estimator' / 'models'\n",
    "\n",
    "years = [2007 + i for i in range(13)]\n",
    "\n",
    "LOG_FILENAME = str(\n",
    "    (Path.cwd() / 'influenza_estimator' / 'information.log').absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_features(path):\n",
    "    if path.exists() and path.is_file():\n",
    "        df = pd.read_csv(path)\n",
    "        features = df.drop(columns=['incidence'])\n",
    "        return features.values\n",
    "\n",
    "\n",
    "def load_labels(path):\n",
    "    if path.exists() and path.is_file():\n",
    "        df = pd.read_csv(path)\n",
    "        labels = pd.Series(df['incidence'])\n",
    "        return labels.values\n",
    "\n",
    "\n",
    "def load(path, is_labels=False):\n",
    "    if path.exists() and path.is_file():\n",
    "        df = pd.read_csv(path)\n",
    "        if is_labels:\n",
    "            df = pd.Series(df['incidence'])\n",
    "        return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "For austria\n(156, 305)\n(156,)\n[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan]\nFor belgium\n(260, 296)\n(260,)\n[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan]\nFor germany\n(312, 304)\n(312,)\n[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan]\nFor italy\n(312, 384)\n(312,)\n[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan]\nFor netherlands\n(260, 296)\n(260,)\n[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n nan nan nan nan nan nan nan nan]\n"
    }
   ],
   "source": [
    "\n",
    "alpha = {\n",
    "    'austria':19.5,\n",
    "    'belgium':84,\n",
    "    'germany':37.5,\n",
    "    'italy':57,\n",
    "    'netherlands':84\n",
    "}\n",
    "\n",
    "main_data_path = Path.cwd() / 'data'\n",
    "df = {}\n",
    "\n",
    "for country in COUNTRIES:\n",
    "            print('For '+country)\n",
    "            main_file_path = main_data_path / (country + '.csv')\n",
    "            df[country] = pd.read_csv(main_file_path)\n",
    "            print(df[country].shape)\n",
    "\n",
    "\n",
    "            x_train_file_path = processed_data_path / (country + '_features.csv')\n",
    "            y_train_file_path = processed_data_path / (country + '_labels.csv')\n",
    "            features_train = sg.create_features(load(x_train_file_path).T)\n",
    "            labels_train = sg.create_labels(load(y_train_file_path, is_labels=True))\n",
    "\n",
    "            lrr = sg.create_machine(\"LinearRidgeRegression\", tau=alpha[country], labels=labels_train, use_bias=False)\n",
    "            lrr.train(features_train)\n",
    "            labels_train_predict = lrr.apply(features_train)\n",
    "            y_train_predicted = labels_train_predict.get(\"labels\").reshape(labels_train_predict.get(\"labels\").shape[0])\n",
    "            print(y_train_predicted.shape)\n",
    "            df[country]['estimate_lrr'] = y_train_predicted\n",
    "\n",
    "            mean_rule = sg.create_combination_rule(\"MeanRule\")\n",
    "            rand_forest = sg.create_machine(\"RandomForest\",\n",
    "                                            labels=labels_train,\n",
    "                                            num_bags=5, seed=1,\n",
    "                                            combination_rule=mean_rule)\n",
    "\n",
    "            rand_forest.train(features_train)\n",
    "            labels_train_predict = rand_forest.apply_regression(features_train)\n",
    "            y_train_predicted = labels_train_predict.get(\"labels\").reshape(labels_train_predict.get(\"labels\").shape[0])\n",
    "            df[country]['estimate_rf'] = y_train_predicted\n",
    "\n",
    "            glm = sg.create_machine(\"GLM\", labels=labels_train, alpha=0.17, learning_rate=0.002, max_iterations=1000, tolerance=0.000001, eta=0.2)\n",
    "            glm.put(\"lambda\", 0.001)\n",
    "            glm.train(features_train)\n",
    "            labels_train_predict = glm.apply(features_train)\n",
    "            y_train_predicted = labels_train_predict.get(\"labels\").reshape(labels_train_predict.get(\"labels\").shape[0])\n",
    "            print(y_train_predicted)\n",
    "            df[country]['estimate_p'] = y_train_predicted\n",
    "\n",
    "#             random_forest[country] = rand_forest\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Unnamed: 0  incidence  Acrocianosi  Acroosteolisi  Adiadococinesia  \\\n0           0       0.19          0.0            0.0              0.0   \n1           1       0.32          0.0            0.0              0.0   \n2           2       0.26          0.0            0.0              0.0   \n3           3       0.41          0.0            0.0              0.0   \n4           4       0.51          0.0            0.0              0.0   \n\n   Alfuy_virus  Alitosi  Allucinazione_uditiva  Anatossina  \\\n0          0.0      0.0                    0.0         0.0   \n1          0.0      0.0                    0.0         0.0   \n2          0.0      0.0                    0.0         0.0   \n3          0.0      0.0                    0.0         0.0   \n4          0.0      0.0                    0.0         0.0   \n\n   Anemia_infettiva_equina     ...      Xantoma  Xerosi  Yaounde_virus  \\\n0                      0.0     ...          0.0     0.0            0.0   \n1                      0.0     ...          0.0     0.0            0.0   \n2                      0.0     ...          0.0     0.0            0.0   \n3                      0.0     ...          0.0     0.0            0.0   \n4                      0.0     ...          0.0     0.0            0.0   \n\n   Yokose_virus        date  estimate     week  estimate_lrr  estimate_rf  \\\n0           0.0  2007-10-21       NaN  2007-42      0.002335     0.424473   \n1           0.0  2007-10-28       NaN  2007-43      0.004615     0.544473   \n2           0.0  2007-11-04       NaN  2007-44      0.005049     0.438473   \n3           0.0  2007-11-11       NaN  2007-45      0.005587     0.544473   \n4           0.0  2007-11-18       NaN  2007-46      0.008879     0.544473   \n\n   estimate_p  \n0         NaN  \n1         NaN  \n2         NaN  \n3         NaN  \n4         NaN  \n\n[5 rows x 387 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>incidence</th>\n      <th>Acrocianosi</th>\n      <th>Acroosteolisi</th>\n      <th>Adiadococinesia</th>\n      <th>Alfuy_virus</th>\n      <th>Alitosi</th>\n      <th>Allucinazione_uditiva</th>\n      <th>Anatossina</th>\n      <th>Anemia_infettiva_equina</th>\n      <th>...</th>\n      <th>Xantoma</th>\n      <th>Xerosi</th>\n      <th>Yaounde_virus</th>\n      <th>Yokose_virus</th>\n      <th>date</th>\n      <th>estimate</th>\n      <th>week</th>\n      <th>estimate_lrr</th>\n      <th>estimate_rf</th>\n      <th>estimate_p</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.19</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2007-10-21</td>\n      <td>NaN</td>\n      <td>2007-42</td>\n      <td>0.002335</td>\n      <td>0.424473</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.32</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2007-10-28</td>\n      <td>NaN</td>\n      <td>2007-43</td>\n      <td>0.004615</td>\n      <td>0.544473</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.26</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2007-11-04</td>\n      <td>NaN</td>\n      <td>2007-44</td>\n      <td>0.005049</td>\n      <td>0.438473</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.41</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2007-11-11</td>\n      <td>NaN</td>\n      <td>2007-45</td>\n      <td>0.005587</td>\n      <td>0.544473</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.51</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2007-11-18</td>\n      <td>NaN</td>\n      <td>2007-46</td>\n      <td>0.008879</td>\n      <td>0.544473</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 387 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df['italy'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_path = Path.cwd() / 'data' / 'final'\n",
    "\n",
    "for country in COUNTRIES:\n",
    "    final_data_file = final_data_path / (country + '.csv')\n",
    "    df[country].to_csv(final_data_file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.5.5 64-bit",
   "language": "python",
   "name": "python35564bite6ddbd5bbab04a30ad6923401d29ed67"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}